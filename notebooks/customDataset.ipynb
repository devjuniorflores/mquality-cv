{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987a0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Leer JSON COCO\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "\n",
    "        # Guardar lista de imágenes\n",
    "        self.imgs = coco_data[\"images\"]\n",
    "        self.annotations = coco_data[\"annotations\"]\n",
    "\n",
    "        # Mapear imagen_id → anotaciones\n",
    "        self.img_id_to_anns = {}\n",
    "        for ann in self.annotations:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id not in self.img_id_to_anns:\n",
    "                self.img_id_to_anns[img_id] = []\n",
    "            self.img_id_to_anns[img_id].append(ann)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.imgs[idx]\n",
    "        img_id = img_info[\"id\"]\n",
    "\n",
    "        # Cargar imagen\n",
    "        img_path = os.path.join(self.img_dir, img_info[\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Obtener anotaciones\n",
    "        anns = self.img_id_to_anns.get(img_id, [])\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            bbox = ann[\"bbox\"]  # [x, y, w, h]\n",
    "            x_min = bbox[0]\n",
    "            y_min = bbox[1]\n",
    "            x_max = x_min + bbox[2]\n",
    "            y_max = y_min + bbox[3]\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf0a5802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([34, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "dataset = CocoDataset(\n",
    "    annotations_file=\"../data/coco/coco_train.json\",\n",
    "    img_dir=\"../data/yolo/images/train\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True,  collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "for imgs, targets in loader:\n",
    "    print(len(imgs)) \n",
    "    print(type(imgs[0]))  # Tensor de la imagen\n",
    "    print(targets[0][\"boxes\"].shape)  # Cantidad variable de boxes\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
