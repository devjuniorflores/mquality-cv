# Sistema de Monitoreo de Calidad

El objetivo de este proyecto es desarrollar un sistema de monitoreo de calidad basado en visi√≥n por computadora, capaz de procesar, anotar, validar y preprocesar datos visuales (im√°genes y videos) de manera automatizada.
El sistema integrar√° manejo de datos, anotaci√≥n en formatos est√°ndar (YOLO, COCO), validaci√≥n y versionado con DVC, preprocesamiento y preparaci√≥n para frameworks de deep learning, y orquestaci√≥n de pipelines con Airflow.
Este flujo permitir√° tener datasets limpios, balanceados y listos para entrenamiento de modelos de detecci√≥n y clasificaci√≥n, asegurando reproducibilidad y escalabilidad.


## üìÇ Estructura inicial del proyecto
```plaintext
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Datos originales (no versionados en Git)
‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Datos procesados
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks
‚îú‚îÄ‚îÄ src/                  # C√≥digo fuente
‚îú‚îÄ‚îÄ .gitignore            # Ignorar data y archivos temporales
‚îú‚îÄ‚îÄ README.md             # Documentaci√≥n principal
```
## Procesamiento y Transformaci√≥n de Frames

En esta etapa del proyecto, el objetivo fue **preprocesar los frames extra√≠dos** para prepararlos para futuras tareas de an√°lisis y modelado.  

### üîπ Actividades realizadas
1. **Lectura de im√°genes con OpenCV**  
   - Uso de `cv2.imread()` para cargar im√°genes desde `data/processed`.
   - Verificaci√≥n de rutas y control de errores para asegurar la carga correcta.

2. **Redimensionamiento (Resize)**  
   - Uso de `cv2.resize()` para normalizar la resoluci√≥n de los frames a un tama√±o est√°ndar (300x300 px).  
   - Esto facilita el procesamiento en modelos de visi√≥n por computadora y reduce el costo computacional.

3. **Recorte (Crop)**  
   - Selecci√≥n de una regi√≥n espec√≠fica de inter√©s (`img[y1:y2, x1:x2]`).  
   - El recorte permite centrar el an√°lisis solo en el √°rea relevante de cada frame, eliminando ruido visual.

4. **Exportaci√≥n de im√°genes procesadas**  
   - Guardado con `cv2.imwrite()` de los nuevos archivos (`resized_opencv.png` y `crop_opencv.png`) para uso en las siguientes fases del pipeline.

### Objetivo
Estandarizar y limpiar los frames para que los datos visuales est√©n listos para an√°lisis, modelado o integraci√≥n en pipelines de visi√≥n por computadora.

## Anotaci√≥n y Etiquetado de Datos 

En esta fase, nos enfocamos en la creaci√≥n y validaci√≥n de datasets anotados para tareas de detecci√≥n de objetos, utilizando herramientas y formatos est√°ndar del ecosistema de visi√≥n por computadora.

### üîπ Actividades realizadas

- Instalaci√≥n y configuraci√≥n de CVAT para anotaci√≥n colaborativa.  
- Importaci√≥n y etiquetado de un conjunto de im√°genes con bounding boxes y asignaci√≥n de clases.  
- Exportaci√≥n de las anotaciones en formatos **YOLO** y **COCO** para m√°xima compatibilidad con frameworks de deep learning.  
- Validaci√≥n manual y automatizada de los archivos de anotaci√≥n YOLO (`.txt`), asegurando que las coordenadas est√©n correctamente normalizadas entre 0 y 1.  
- Exploraci√≥n de la estructura del archivo JSON de COCO, identificando y comprendiendo sus componentes clave: `images`, `annotations` y `categories`.

### üîπ Resultados y aprendizajes clave

- Comprensi√≥n profunda de los formatos de anotaci√≥n y su impacto en el entrenamiento de modelos.  
- Implementaci√≥n de un script en Python para validar la calidad y consistencia de las anotaciones YOLO, reduciendo errores y mejorando la confiabilidad del dataset. (validacion_txtYolo.ipynb) 
- Familiarizaci√≥n con el flujo completo de anotaci√≥n, exportaci√≥n y validaci√≥n, sentando las bases para la integraci√≥n con pipelines de entrenamiento.

### Objetivo
Consolidar un flujo completo y confiable de anotaci√≥n y validaci√≥n de datos visuales, utilizando formatos est√°ndar (YOLO y COCO), que permita generar datasets de alta calidad listos para entrenamiento de modelos de visi√≥n por computadora. Esto asegura que las anotaciones sean precisas, consistentes y compatibles con m√∫ltiples frameworks, facilitando el desarrollo eficiente y escalable de soluciones de detecci√≥n y clasificaci√≥n.

## Validaci√≥n de Dataset y Configuraci√≥n de Remoto S3 con DVC

### üîç Actividades realizadas
- Verificaci√≥n de que las etiquetas coincidan con las im√°genes y registro de las que no est√°n etiquetadas en un `.csv`.
- Detecci√≥n de im√°genes **duplicadas** (mismo hash) y **corruptas** (archivos incompletos o ilegibles).
- Comprensi√≥n de la estructura interna del cache de DVC (`.dvc/cache`), con subcarpetas basadas en los primeros 2 caracteres del hash.
- Ejecuci√≥n de `dvc push` para subir el dataset validado al bucket S3.

### üìö Conocimientos consolidados
- Uso de **hashes SHA-256** para identificar y deduplicar archivos.
- Relaci√≥n entre cache local de DVC y almacenamiento remoto.

### Objetivo
Validar la integridad y consistencia del dataset, eliminando duplicados y detectando archivos corruptos, para luego configurar y subir el conjunto de datos a un almacenamiento remoto en Amazon S3 mediante DVC.

## Preprocesamiento

### üîπ Actividades realizadas
1. **Resize uniforme** de las im√°genes a dimensiones est√°ndar (ej. `640x640`).
2. **Normalizaci√≥n** de valores de p√≠xeles a escala `[0,1]` (px/255).
3. **Data augmentation** con rotaciones, flips, y blur para aumentar diversidad.
4. **Balanceo de clases** mediante t√©cnicas de oversampling (creaci√≥n de datos sint√©ticos).
5. **Estructuraci√≥n final** del dataset en `data/processed/` manteniendo subcarpetas por clase.
6. **Creaci√≥n de validador** para verificar integridad y conteo de im√°genes por clase.
7. **Discusi√≥n sobre versionado con DVC**:
   - **Versionar:** `raw/` y `processed/`
   - **No versionar:** `temp/` (datos intermedios regenerables)

---

### üìå Conocimientos reforzados
- Identificaci√≥n y correcci√≥n de **desbalance de clases**.
- Importancia de la **normalizaci√≥n de datos** y escalas correctas (`[0,1]` o `[-1,1]`).
- Uso de **data augmentation** para robustecer el modelo.
- Buenas pr√°cticas en **gobernanza de datos** con DVC.
- Diferencia entre datos **intermedios** y datos **versionables**.

  **Objetivo del d√≠a:**  
Implementar el pipeline de preprocesamiento y dejar el dataset listo para entrenamiento.
